{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data file from the compressed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas  as pd\n",
    "with gzip.open('DScasestudy (1) (50).txt.gz') as file:\n",
    "\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "#check the structure of the data\n",
    "    data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530 entries, 0 to 529\n",
      "Columns: 16563 entries, response to V16562\n",
      "dtypes: int64(16563)\n",
      "memory usage: 67.0 MB\n"
     ]
    }
   ],
   "source": [
    "#get general information on the data(# of columns and rows, what data types)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any data points that is empty since it will affect the model performance in this case\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many unique values in the response column to check whether its a binary or multiclass classification\n",
    "data['response'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    530.000000\n",
       "mean       0.232075\n",
       "std        0.422556\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000\n",
       "Name: response, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get more statistical information on the response column. The results show that there are 530 values with mean 0.234 \n",
    "#and standard deviation of 0.422. The 1st, 2nd and third quartile are 0 and the max 1. So a class imbalance does exists in response.\n",
    "data['response'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 407, 30.22113022113022, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analyse the response feature further to understand the class imbalance. There are 123 responses with 1 and 407 with 0 response, in the ratio 1:3 \n",
    "sum(data['response']== 1), sum(data['response']== 0), ((123/407)*100), int(407/123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some features to improve model performance: I tried to remove the columns that are not relevant for the response ie., \n",
    "#they do not change irrespective of positive or negative response. This process removed more than 6000 features that could speed up the training process as well improve the model performance.\n",
    "for col in data.columns:\n",
    "    if data[col].nunique() == 1:\n",
    "        data.drop(col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling class imbalance: one of the ways to handle class imbalance is either downsample the minority class or upsample the majority class. We could also try data augmentation to synthesize more minority class samples with some variations. I have tried the downsampling of the majority class here and the upsampling of the minority class here. So that there will be enough number of samples for both classes to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    123\n",
       "0    123\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data based on response\n",
    "res_0 = data[data['response']== 0] #negative response only\n",
    "res_1 = data[data['response']== 1] #positive response only\n",
    "from sklearn.utils import resample\n",
    "#downsampling the majority class\n",
    "neg_downsampled = resample(res_0, replace=True, n_samples=123, random_state=50)\n",
    "# Combine the minority class with downsampled majority class\n",
    "downsample = pd.concat([neg_downsampled, res_1])\n",
    "#the new class counts\n",
    "downsample.response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    204\n",
       "0    123\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upsampling the data\n",
    "pos_upsampled = resample(res_1, replace=True, n_samples=81, random_state=50)\n",
    "# Combine upsampled minority class with downsampled data\n",
    "upsample = pd.concat([pos_upsampled, downsample])\n",
    "#the new class counts\n",
    "upsample.response.value_counts()\n",
    "\n",
    "#here we have slightly more positive samples (81)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the data into X (independent) and y (dependent) features\n",
    "X = upsample.loc[:,upsample.columns != 'response'].values\n",
    "y = upsample.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling sparse matrix, since there are a lot of zeros in the independent variables and it helps to \n",
    "#convert it to sparse matrix to improve model performance\n",
    "from scipy.sparse import csr_matrix\n",
    "X_csr = csr_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection and parameter tuning: I have chosen the xgboost classifier algorithm for this classification problem since it is a fast and flexible algorithm with great performance. It is a gradient boosting decision tree algorithm. The boosting reduces high bias and high variance. The gridsearchcv algorithm is used to tune the parameters of the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2187 out of 2187 | elapsed: 35.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'reg_lambda': [0.2,0.4,0.6],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.1, 0.3, 0.5],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'scale_pos_weight': [1,3,5]\n",
    "        }\n",
    "\n",
    "cls = XGBClassifier(learning_rate=0.02, n_estimators=100, objective='binary:logistic',  silent=True, nthread = -1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle = True, random_state = 5)\n",
    "\n",
    "# if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used\n",
    "gridsearch = GridSearchCV(estimator=cls, param_grid=params, scoring='roc_auc', n_jobs=-1, cv=skf.split(X,y), return_train_score=True, verbose=3 )\n",
    "gridsearch.fit(X, y)\n",
    "cvresults = pd.DataFrame(gridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the X and y data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_csr,y, test_size=0.30, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.010101\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0\n",
      "[2]\tvalidation_0-error:0\n",
      "[3]\tvalidation_0-error:0\n",
      "[4]\tvalidation_0-error:0\n",
      "[5]\tvalidation_0-error:0\n",
      "[6]\tvalidation_0-error:0\n",
      "[7]\tvalidation_0-error:0\n",
      "[8]\tvalidation_0-error:0\n",
      "[9]\tvalidation_0-error:0\n",
      "[10]\tvalidation_0-error:0\n",
      "[11]\tvalidation_0-error:0\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-error:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use the best parameters from the gridsearch to train the model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "n_estimators=1400, objective = 'binary:logistic', learning_rate = 0.02, reg_lambda = 0.2, scale_pos_weight = 3, max_depth =3, colsample_bytree = 0.1, #try changing colsample6\n",
    "            subsample =0.6, min_child_weight =1, tree_method = \"auto\", nthread = -1, random_state = 50)\n",
    "\n",
    "eval_set = [(X_test, y_test)]\n",
    "\n",
    "model.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, early_stopping_rounds = 10, verbose=True)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance metrices for the model: accuracy, confusion matrix and precision/recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#performance\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:1</th>\n",
       "      <th>pred:0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:0</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred:1  pred:0\n",
       "true:1       1       0\n",
       "true:0       0      98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame(metrics.confusion_matrix(y_test, y_pred, labels=[1, 0]), index=['true:1', 'true:0'], columns=['pred:1', 'pred:0'])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision = TP / (TP+FP)\n",
    "precision = conf_matrix.iloc[0,0] / (conf_matrix.iloc[0,0]+conf_matrix.iloc[1,0])\n",
    "#recall = TP / (TP+FN)\n",
    "recall = conf_matrix.iloc[0,0] / (conf_matrix.iloc[0,0]+conf_matrix.iloc[0,1])\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only probabilities can be used for roc_auc\n",
    "# Predict class probabilities\n",
    "prob_y = model.predict_proba(X_test)\n",
    "# Keep only the positive class\n",
    "prob_y = [p[1] for p in prob_y]\n",
    "metrics.roc_auc_score(y_test, prob_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough the prediction accuracy is 100% for this particular sample(small) with more data we may have a better way to adjudge the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
